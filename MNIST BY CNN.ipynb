{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJxfx1CpjpSSPoEXv6RwhH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grantzhou123/mnist/blob/main/MNIST%20BY%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nVTGvx18U0go"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNNモデルの定義\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QJGpVHqlVk9B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの準備\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # MNISTのデータの平均と標準偏差に基づく正規化\n",
        "])"
      ],
      "metadata": {
        "id": "0t-4iyldYss1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNISTデータセットのロード\n",
        "train_dataset = datasets.MNIST(root='./data', train=True,\n",
        "                               transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False,\n",
        "                               transform=transform, download=True)\n",
        "\n",
        "# DataLoaderの設定\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iphSatoSZGG3",
        "outputId": "928eaf10-b05a-4a21-b082-415aabad272a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 42144664.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24616072.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 11216862.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3564844.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# デバイスの設定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "v2w4RWLQZOGH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル、損失関数、最適化手法の設定\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "# 学習率スケジューラの設定（オプショナル）\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)"
      ],
      "metadata": {
        "id": "tDmBY8BXZl7F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練ループ\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # 訓練モードに設定\n",
        "    loss_epoch = 0.0\n",
        "    for data in train_loader:\n",
        "        img, label = data\n",
        "        img, label = img.to(device), label.to(device)\n",
        "        output = model(img)\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_epoch += loss.item()\n",
        "    scheduler.step()  # 学習率の更新\n",
        "    print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {loss_epoch:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grOfZQNXZwXu",
        "outputId": "813c377b-45b7-42e9-cd1f-deaa73ed1513"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10, Loss: 1642.2933\n",
            "Epoch: 2/10, Loss: 551.7734\n",
            "Epoch: 3/10, Loss: 372.6508\n",
            "Epoch: 4/10, Loss: 324.4454\n",
            "Epoch: 5/10, Loss: 301.9901\n",
            "Epoch: 6/10, Loss: 289.1421\n",
            "Epoch: 7/10, Loss: 281.0123\n",
            "Epoch: 8/10, Loss: 275.8249\n",
            "Epoch: 9/10, Loss: 272.5162\n",
            "Epoch: 10/10, Loss: 269.9552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの保存\n",
        "torch.save(model.state_dict(), 'mnist_cnn.pth')"
      ],
      "metadata": {
        "id": "xe8l5rosZ2F1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データとテストデータでのモデルの評価\n",
        "def evaluate_model(loader):\n",
        "    model.eval()  # 評価モードに設定\n",
        "    labels_true = []\n",
        "    labels_pred = []\n",
        "    with torch.no_grad():\n",
        "        for img, label in loader:\n",
        "            labels_true.extend(label.numpy())\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            output = model(img)\n",
        "            _, pred = torch.max(output.data, 1)\n",
        "            pred = pred.cpu().numpy()\n",
        "            labels_pred.extend(pred)\n",
        "    print(confusion_matrix(labels_true, labels_pred))\n",
        "    print(classification_report(labels_true, labels_pred))"
      ],
      "metadata": {
        "id": "72FWJTczZ6wP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"訓練データでの評価:\")\n",
        "evaluate_model(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt1uJeWkZ_8A",
        "outputId": "a934ded2-ae7b-4d14-94a6-5d38b6eab831"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データでの評価:\n",
            "[[5709    4   16   12    6   38   47    9   74    8]\n",
            " [   1 6531   56   26    9   36    7   13   54    9]\n",
            " [  46   36 5332   83  131   14   87  100  116   13]\n",
            " [  22   47  128 5456    6  197   18   85  116   56]\n",
            " [   5   21   59    2 5331    2   88   13   33  288]\n",
            " [  42   42   34  140   92 4867   73   15   73   43]\n",
            " [  45   55   32    0   42   92 5623    2   27    0]\n",
            " [  17   55  103   17   51   13    0 5769   10  230]\n",
            " [  23  123   49  151   41  107   26   19 5204  108]\n",
            " [  36   38   44   97  156   20    3  182   51 5322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96      5923\n",
            "           1       0.94      0.97      0.95      6742\n",
            "           2       0.91      0.89      0.90      5958\n",
            "           3       0.91      0.89      0.90      6131\n",
            "           4       0.91      0.91      0.91      5842\n",
            "           5       0.90      0.90      0.90      5421\n",
            "           6       0.94      0.95      0.95      5918\n",
            "           7       0.93      0.92      0.93      6265\n",
            "           8       0.90      0.89      0.90      5851\n",
            "           9       0.88      0.89      0.89      5949\n",
            "\n",
            "    accuracy                           0.92     60000\n",
            "   macro avg       0.92      0.92      0.92     60000\n",
            "weighted avg       0.92      0.92      0.92     60000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"テストデータでの評価:\")\n",
        "evaluate_model(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvaDXHNWaDtb",
        "outputId": "63a572eb-9c45-486d-fff1-db93e1c720f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "テストデータでの評価:\n",
            "[[ 961    0    0    0    0    4    8    1    6    0]\n",
            " [   0 1110    4    3    1    1    3    0   13    0]\n",
            " [  10    1  930   15   14    1   13   18   28    2]\n",
            " [   3    2   20  925    0   20    0   15   19    6]\n",
            " [   1    3    5    0  906    0   16    1    5   45]\n",
            " [   8    3    5   31   11  799   12    1   17    5]\n",
            " [  12    6    3    1   11   20  905    0    0    0]\n",
            " [   0   11   27    4    7    1    0  927    4   47]\n",
            " [   7    7    6   22   12   17    5   11  874   13]\n",
            " [   7    6    7   10   24   10    0   17    8  920]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       980\n",
            "           1       0.97      0.98      0.97      1135\n",
            "           2       0.92      0.90      0.91      1032\n",
            "           3       0.91      0.92      0.92      1010\n",
            "           4       0.92      0.92      0.92       982\n",
            "           5       0.92      0.90      0.91       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.94      0.90      0.92      1028\n",
            "           8       0.90      0.90      0.90       974\n",
            "           9       0.89      0.91      0.90      1009\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.92      0.92     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 単一画像に対するモデルの予測を表示する関数\n",
        "def show_prediction_example(loader):\n",
        "    model.eval()  # 評価モードに設定\n",
        "    images, labels = next(iter(loader))  # データローダーから一批のデータを取得\n",
        "\n",
        "    # GPUが利用可能な場合は、画像をGPUに移動\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    output = model(images)  # モデルで予測\n",
        "    _, preds = torch.max(output, 1)  # 最も高い確率を持つクラスを予測ラベルとして選択\n",
        "\n",
        "    # 予測結果の表示\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for idx in np.arange(4):  # 最初の4つの画像と予測ラベルを表示\n",
        "        ax = plt.subplot(1, 4, idx+1)\n",
        "        img = images[idx].cpu().numpy().squeeze()  # 画像を表示用に変換\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.set_title(f\"Predicted: {preds[idx].item()}\", color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# テストデータローダーを使用して予渲例を表示\n",
        "show_prediction_example(test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "DZ4_YMceEZEc",
        "outputId": "7a31f0e6-7f66-4d14-b99f-01ae8890f7d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}